{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        torch.nn.Module.__init__(self)\n",
    "\n",
    "        self.num_outputs = 0\n",
    "        self.parameters_count = None\n",
    "        self.total_parameters = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return current pytorch gradient in same order as genome's flattened parameter vector\n",
    "class NetModule(NetModule):\n",
    "    def extract_grad(self):\n",
    "        pvec = np.zeros(self.parameters_count, np.float32)\n",
    "        count = 0\n",
    "        is_cuda = self.is_cuda()\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad:\n",
    "                sz = self.mul(param)\n",
    "                data = param.grad.data.cpu() if is_cuda else param.grad.data\n",
    "                pvec[count:count + sz] = data.numpy().flatten()\n",
    "                count += sz\n",
    "        return pvec.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetModule(NetModule):\n",
    "    # function to grab current flattened neural network weights\n",
    "    def extract_parameters(self):\n",
    "        pvec = np.zeros(self.parameters_count, np.float32)\n",
    "        count = 0\n",
    "        is_cuda = self.is_cuda()\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad:\n",
    "                sz = self.mul(param)\n",
    "                data = param.data.cpu() if is_cuda else param.data\n",
    "                pvec[count:count + sz] = data.numpy().flatten()\n",
    "                count += sz\n",
    "        return pvec.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetModule(NetModule):\n",
    "    # function to inject a flat vector of ANN parameters into the model's current neural network weights\n",
    "    def inject_parameters(self, pvec):\n",
    "        assert len(pvec) == self.parameters_count\n",
    "        pvec = np.asarray(pvec, dtype=np.float32)\n",
    "        count = 0\n",
    "        is_cuda = self.is_cuda()\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad:\n",
    "                sz = self.mul(param)\n",
    "                raw = pvec[count:count + sz]\n",
    "                data = param.data.cpu() if is_cuda else param.data\n",
    "                reshaped = raw.reshape(data.numpy().shape)\n",
    "                param.data = torch.from_numpy(reshaped)\n",
    "                if is_cuda:\n",
    "                    param.data = param.data.cuda()\n",
    "                count += sz\n",
    "\n",
    "        return pvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetModule(NetModule):\n",
    "    # count how many parameters are in the model\n",
    "    def count_parameters(self):\n",
    "        self.parameters_count = sum(self.mul(param) for param in self.parameters() if param.requires_grad)\n",
    "        self.total_parameters = sum(self.mul(param) for param in self.parameters())\n",
    "\n",
    "        return self.parameters_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetModule(NetModule):\n",
    "    def is_cuda(self):\n",
    "        return next(self.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetModule(NetModule):\n",
    "    @staticmethod\n",
    "    def mul(x):\n",
    "        prod = 1\n",
    "        for z in list(x.size()):\n",
    "            prod *= z\n",
    "        return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetModule(NetModule):\n",
    "    def forward(self, *inputs):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
